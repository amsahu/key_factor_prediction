{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13645, 22) (8745, 20)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13645, 22)\n",
      "(13645, 16)\n",
      "(13645, 17)\n",
      "(13645, 46) (13645,)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "\n",
    "train1 = train[[ 'LanguageOfCommunication', 'Age', 'Gender',\n",
    "       'JobProfileIDApplyingFor', 'HighestDegree', 'DegreeBranch',\n",
    "       'GraduatingInstitute', 'LatestDegreeCGPA', 'YearsOfExperince',\n",
    "       'CurrentCTC', 'MartialStatus',\n",
    "       'EmpScore', 'CurrentDesignation', 'CurrentCompanyType',\n",
    "       'DepartmentInCompany', 'TotalLeavesTaken']].copy()\n",
    "print(train1.shape)\n",
    "\n",
    "train1['GraduatingInstitute'] = train['GraduatingInstitute'].map({'Tier 1':3,'Tier 2':2, 'Tier 3':1})\n",
    "train1['ExpectedHike'] = (train['ExpectedCTC']-train['CurrentCTC'])/train['CurrentCTC']*100\n",
    "print(train1.shape)\n",
    "\n",
    "target_col = train['BiasInfluentialFactor'].fillna('Unknown')\n",
    "\n",
    "X = pd.get_dummies(train1, drop_first=True).values\n",
    "y = target_col.copy().values\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10916, 46) (2729, 46) (10916,) (2729,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_en = le.fit_transform(y)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train,y_val = train_test_split(X,y_en, test_size=.2, stratify=y_en,random_state=123)\n",
    "print(X_train.shape, X_val.shape, y_train.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10916, 46) (10916,)\n",
      "(12127, 46) (12127,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "sampling_strategy_dict={\n",
    " 2: 700,\n",
    " 5: 700,\n",
    " 3: 500,\n",
    " 7: 500,\n",
    " 6: 500}\n",
    "\n",
    "sm = SMOTE( sampling_strategy=sampling_strategy_dict,\n",
    "              random_state=123, n_jobs=-1)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_train_res.shape, y_train_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14856, 46) (14856,)\n"
     ]
    }
   ],
   "source": [
    "X_final = np.concatenate([X_train_res,X_val])\n",
    "y_final = np.concatenate([y_train_res,y_val])\n",
    "print(X_final.shape,y_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7765351154508043,\n",
       "              gamma=4.545832475162831, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.07231521329322932,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=18.0, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=1000, n_jobs=-1,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=0.8465452157807187, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_clf_xgb = XGBClassifier(verbosity=1, n_estimators=1000, objective='multi:softmax',\n",
    "                        use_label_encoder=False, n_jobs=-1, num_parallel_tree=1,\n",
    "                       colsample_bytree= 0.7765351154508043,\n",
    "                     gamma= 4.545832475162831,\n",
    "                     learning_rate= 0.07231521329322932,\n",
    "                     max_depth= 6,\n",
    "                     min_child_weight= 18.0,\n",
    "                     subsample= 0.8465452157807187)\n",
    "\n",
    "model_clf_xgb.fit(X_final,y_final, eval_metric=['mlogloss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13645, 22)\n",
      "(13645, 16)\n",
      "(13645, 18)\n",
      "(13645, 55) (13645,)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "\n",
    "train2 = train[[ 'LanguageOfCommunication', 'Age', 'Gender',\n",
    "       'JobProfileIDApplyingFor', 'HighestDegree', 'DegreeBranch',\n",
    "       'GraduatingInstitute', 'LatestDegreeCGPA', 'YearsOfExperince',\n",
    "       'CurrentCTC', 'MartialStatus',\n",
    "       'EmpScore', 'CurrentDesignation', 'CurrentCompanyType',\n",
    "       'DepartmentInCompany', 'TotalLeavesTaken']].copy()\n",
    "print(train2.shape)\n",
    "\n",
    "train2['GraduatingInstitute'] = train['GraduatingInstitute'].map({'Tier 1':3,'Tier 2':2, 'Tier 3':1})\n",
    "train2['ExpectedHike'] = (train['ExpectedCTC']-train['CurrentCTC'])/train['CurrentCTC']*100\n",
    "train2['BiasInfluentialFactor'] = train['BiasInfluentialFactor'].fillna('Unknown')\n",
    "print(train2.shape)\n",
    "\n",
    "target_col2 = train['FitmentPercent']\n",
    "\n",
    "X2 = pd.get_dummies(train2, drop_first=True).values\n",
    "y2 = target_col2.copy().values\n",
    "print(X2.shape,y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor : xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8026236086240719,\n",
       "             gamma=7.949076522205543, gpu_id=-1, importance_type='gain',\n",
       "             interaction_constraints='', learning_rate=0.09093358640056634,\n",
       "             max_delta_step=0, max_depth=7, min_child_weight=16.0, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=500, n_jobs=-1,\n",
       "             num_parallel_tree=5, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, subsample=0.9292019673341835,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_rg_xgb = XGBRegressor(verbosity=1, n_estimators=500,\n",
    "                         n_jobs=-1, num_parallel_tree=5,\n",
    "                       colsample_bytree= 0.8026236086240719,\n",
    "                         gamma= 7.949076522205543,\n",
    "                         learning_rate= 0.09093358640056634,\n",
    "                         max_depth= 7,\n",
    "                         min_child_weight= 16.0,\n",
    "                         subsample= 0.9292019673341835)\n",
    "\n",
    "model_rg_xgb.fit(X2,y2, eval_metric=['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressor : lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 316\n",
      "[LightGBM] [Info] Number of data points in the train set: 13645, number of used features: 55\n",
      "[LightGBM] [Info] Start training from score 75.880093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.7788161685191014,\n",
       "              learning_rate=0.07217558041072707, max_depth=8,\n",
       "              min_child_weight=9.0, n_estimators=500,\n",
       "              reg_alpha=0.5121021692895791, reg_lambda=0.5437507642672469,\n",
       "              subsample=0.9456987855642878, verbosity=1)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model_rg_lgbm = LGBMRegressor(verbosity=1, n_estimators=500,\n",
    "                         n_jobs=-1,\n",
    "                         colsample_bytree= 0.7788161685191014,\n",
    "                         learning_rate=0.07217558041072707,\n",
    "                         max_depth= 8,\n",
    "                         min_child_weight= 9.0,\n",
    "                         reg_alpha= 0.5121021692895791,\n",
    "                         reg_lambda= 0.5437507642672469,\n",
    "                         subsample= 0.9456987855642878\n",
    "                        )\n",
    "\n",
    "model_rg_lgbm.fit(X2,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8745, 20)\n",
      "(8745, 16)\n",
      "(8745, 17)\n",
      "(8745, 46)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "\n",
    "test1 = test[[ 'LanguageOfCommunication', 'Age', 'Gender',\n",
    "       'JobProfileIDApplyingFor', 'HighestDegree', 'DegreeBranch',\n",
    "       'GraduatingInstitute', 'LatestDegreeCGPA', 'YearsOfExperince',\n",
    "       'CurrentCTC', 'MartialStatus',\n",
    "       'EmpScore', 'CurrentDesignation', 'CurrentCompanyType',\n",
    "       'DepartmentInCompany', 'TotalLeavesTaken']].copy()\n",
    "print(test1.shape)\n",
    "\n",
    "test1['GraduatingInstitute'] = test['GraduatingInstitute'].map({'Tier 1':3,'Tier 2':2, 'Tier 3':1})\n",
    "test1['ExpectedHike'] = (test['ExpectedCTC']-test['CurrentCTC'])/test['CurrentCTC']*100\n",
    "print(test1.shape)\n",
    "\n",
    "X_test = pd.get_dummies(test1, drop_first=True).values\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clf = le.inverse_transform(model_clf_xgb.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8745, 20)\n",
      "(8745, 16)\n",
      "(8745, 18)\n",
      "(8745, 55)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "\n",
    "test2 = test[[ 'LanguageOfCommunication', 'Age', 'Gender',\n",
    "       'JobProfileIDApplyingFor', 'HighestDegree', 'DegreeBranch',\n",
    "       'GraduatingInstitute', 'LatestDegreeCGPA', 'YearsOfExperince',\n",
    "       'CurrentCTC', 'MartialStatus',\n",
    "       'EmpScore', 'CurrentDesignation', 'CurrentCompanyType',\n",
    "       'DepartmentInCompany', 'TotalLeavesTaken']].copy()\n",
    "print(test2.shape)\n",
    "\n",
    "test2['GraduatingInstitute'] = test['GraduatingInstitute'].map({'Tier 1':3,'Tier 2':2, 'Tier 3':1})\n",
    "test2['ExpectedHike'] = (test['ExpectedCTC']-test['CurrentCTC'])/test['CurrentCTC']*100\n",
    "test2['BiasInfluentialFactor'] = y_pred_clf\n",
    "print(test2.shape)\n",
    "\n",
    "\n",
    "X_test2 = pd.get_dummies(test2, drop_first=True).values\n",
    "print(X_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rg_xgb = model_rg_xgb.predict(X_test2)\n",
    "y_pred_rg_lgbm = model_rg_lgbm.predict(X_test2)\n",
    "\n",
    "y_pred_rg = (y_pred_rg_xgb+y_pred_rg_lgbm)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmpID</th>\n",
       "      <th>BiasInfluentialFactor</th>\n",
       "      <th>FitmentPercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5664</td>\n",
       "      <td>DegreeBranch</td>\n",
       "      <td>89.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23568</td>\n",
       "      <td>DegreeBranch</td>\n",
       "      <td>92.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21490</td>\n",
       "      <td>MartialStatus</td>\n",
       "      <td>82.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6165</td>\n",
       "      <td>Gender</td>\n",
       "      <td>80.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmpID BiasInfluentialFactor  FitmentPercent\n",
       "0   5664          DegreeBranch           89.29\n",
       "1  23568          DegreeBranch           92.56\n",
       "2  21490         MartialStatus           82.56\n",
       "3   8363                   NaN           45.87\n",
       "4   6165                Gender           80.69"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = test[['EmpID']].copy().reset_index(drop=True)\n",
    "sub['BiasInfluentialFactor'] = np.where(y_pred_clf=='Unknown',np.nan,y_pred_clf)\n",
    "sub['FitmentPercent'] = np.around(y_pred_rg, decimals=2)\n",
    "\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission_file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
